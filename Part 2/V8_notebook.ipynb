{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Credit Risk\n",
    "\n",
    "## Making Predictions\n",
    "Now that the feature columns have been cleaned and prepared for modelling, I can start using the data to make predictions. \n",
    "\n",
    "Although I need to remember the class imbalance in my target column, `loan_status`. There are six times as many loans that were paid off on time (`1`) than those that weren't (`0`). I will keep this in mind as I build my machine learning models.\n",
    "\n",
    "### Error Metric\n",
    "Before I start, I should pick an error metric. Since I am viewing the problem as a conservative investor, I would want to minimize risk and avoid false positives as much as possible. Due to class imbalance, I should measure error using the rate of true and false negatives and positives instead of using accuracy. This means I will optimize for high recall (true positive rate) and low fall-out (false positive rate).\n",
    "\n",
    "### Logistic Regression\n",
    "Logistic regression is a good first algorithm to apply to binary classification problems because it is quick to train, easy to interpret, and is less prone to overfitting than more complex models like decision trees. In order to get a realistic depiction of the accuracy of the model, I will perform k-fold cross validation to further avoid overfitting. This is how I will get my initial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989121566494424\n",
      "0.9967943009795192\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#bring in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "loans = pd.read_csv('loans_clean_V2.csv')\n",
    "\n",
    "#import algorithms for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#instantiating the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#getting feature columns from df\n",
    "cols = loans.columns\n",
    "train_cols = cols.drop('loan_status')\n",
    "\n",
    "#setting feature and target\n",
    "features = loans[train_cols]\n",
    "target = loans['loan_status']\n",
    "\n",
    "#performing 3-fold cross validation\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "\n",
    "#convert predictions to pandas series\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#calculating false positive and true positive rate\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)\n",
    "print(predictions.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the model is predicting all 1s which is resulting in a high accuracy despite not using accuracy as an error metric. It also isn't accounting for the imbalance in the classes. I need to implement a way to tell the classifier to correct for imbalanced classes. I can do this by having the classifier penalize misclassifications of the less prevalent class more than the other class. \n",
    "\n",
    "### Penalizing the Classifier\n",
    "By setting the `class_weight` parameter to `balanced` when creating the Logistic Regression instance, I can have the classifier pay more attention to correctly classifying rows where `loan_status = 0`. As a result, accuracy will decrease when `loan_status = 1` and increase when it equals `0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6593237240504034\n",
      "0.3796972395369546\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "#performing 3-fold cross validation\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "\n",
    "#convert predictions to pandas series\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#calculating false positive and true positive rate\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to significantly improve the false positive rate by balancing the classes, which reduced the true positive rate. The true positive rate is now about 66% and the false positive rate is about 38%. From a conservative investor's standpoint, it's reassuring that the false positive rate is lower because it means that I'll be able to do a better job at avoiding bad loans than if I funded everything. However, I would only ever decide to fund 66% of the total loans (true positive rate), and reject a good amount of loans.\n",
    "\n",
    "I could try to lower the false positive rate furhter by assigning a harsher penalty for misclassifications. For the model below I will pass in a  dictionary to implement a penalty of 10 for misclassifying a 0, and a penalty of 1 for misclassifying a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23560873900824947\n",
      "0.08708815672306322\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight={\n",
    "    0: 10,\n",
    "    1: 1\n",
    "})\n",
    "\n",
    "#performing 3-fold cross validation\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "\n",
    "#convert predictions to pandas series\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#calculating false positive and true positive rate\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like assigning manual penalties lowered the false positive rate to 9%, and lowered our risk. This comes at the expense of true positive rate. While I have fewer false positives, I'm also missing opportunities to fund more loans and potentially make more money. Given that I am approaching this as a conservative investor, this strategy makes sense, but it's worth keeping in mind the tradeoffs. I'll move on to try a different model.\n",
    "\n",
    "\n",
    "### Random Forests\n",
    "Training a random forest algorithm may allow me to get more accuracy due to the columns that correlate nonlinearly with `loan_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709304082434351\n",
      "0.9271593944790739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#instantiating the model\n",
    "rfc = RandomForestClassifier(random_state=1, class_weight='balanced')\n",
    "\n",
    "#performing 3-fold cross validation\n",
    "predictions = cross_val_predict(rfc, features, target, cv=3)\n",
    "\n",
    "#convert predictions to pandas series\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#calculating false positive and true positive rate\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Unfortunately, using a random forest classifier didn't improve the false positive rate. The model is probably weighting too heavily on the `1` class and still predicting mostly `1s`. I could apply a harsher penalty for misclassifications of `0s` like I did for the logistic regression. However, my best model had a false positive rate of 9% and a true positive rate of 24%. At these rates, a conservative investor will make money as long as the interest rate is high enough to offset the losses from 9% of borrowers defaulting, or that the pool of 24% of borrowers is large enough to make enough interest money to offset the loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
